///////////////////////////////////////////////////////////////////////////////

    Copyright (c) 2021, 2025 Oracle and/or its affiliates.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

///////////////////////////////////////////////////////////////////////////////

ifndef::rootdir[:rootdir: {docdir}/../..]

// tag::intro[]

This guide describes how to create a sample Helidon {intro-project-name} project
that can be used to run some basic examples using both built-in and custom {metrics} with Helidon.

== What You Need

For this 30 minute tutorial, you will need the following:

include::{rootdir}/includes/prerequisites.adoc[tag=prerequisites-helm]

// end::intro[]

// tag::create-sample-project[]

=== Create a Sample Helidon {h1-prefix} Project

Use the Helidon {h1-prefix} Maven archetype to create a simple project that can be used for the examples in this guide.

[source,bash,subs="attributes+"]
.Run the Maven archetype
----
mvn -U archetype:generate -DinteractiveMode=false \
    -DarchetypeGroupId=io.helidon.archetypes \
    -DarchetypeArtifactId=helidon-quickstart-{flavor-lc} \
    -DarchetypeVersion={helidon-version} \
    -DgroupId=io.helidon.examples \
    -DartifactId=helidon-quickstart-{flavor-lc} \
    -Dpackage=io.helidon.examples.quickstart.{flavor-lc}
----
// end::create-sample-project[]

// tag::using-built-in-metrics-intro[]
=== Using the Built-In {metrics_uc}

Helidon provides three built-in scopes of metrics: base, vendor, and application. Here are the metric endpoints:

1. `{metrics-endpoint}?scope=base` - Base {metrics}
ifdef::mp-flavor[as specified by the MicroProfile Metrics specification]
2. `{metrics-endpoint}?scope=vendor` - Helidon-specific {metrics}
3. `{metrics-endpoint}?scope=application` - Application-specific metrics data.

Applications can add their own custom scopes as well simply by specifying a custom scope name when registering a {metric}.

NOTE: The `{metrics-endpoint}` endpoint returns data for all scopes.

The built-in {metrics} fall into these categories:

. JVM behavior (in the base scope), and
. basic key performance indicators for request handling (in the vendor scope).

A later section describes the <<basic-and-extended-kpi,key performance indicator {metrics}>> in detail.

The following example demonstrates how to use the other built-in {metrics}.  All examples are executed
from the root directory of your project (helidon-quickstart-{flavor-lc}).
// end::using-built-in-metrics-intro[]

// tag::metrics-dependency[]
----
<dependency>
    <groupId>io.helidon.metrics</groupId>
    <artifactId>helidon-metrics</artifactId>
</dependency>
----
// end::metrics-dependency[]

// tag::build-and-run-intro[]

[source,bash,subs="attributes+"]
.Build the application and then run it:
----
mvn package
java -jar target/helidon-quickstart-{flavor-lc}.jar
----

NOTE: Metrics output can be returned in either text format (the default), or JSON.  The text format uses OpenMetrics (Prometheus) Text Format,
see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details.

[source,bash,subs="attributes+"]
.Verify the metrics endpoint in a new terminal window:
----
curl http://localhost:8080{metrics-endpoint}
----
// end::build-and-run-intro[]

///////////////////////////////////////////////////////////////////////////////
// Referrer must set :prom-output-scope-prefix: to mp_ if the output is to match MP (the scope tag name is mp_scope) and to empty to match SE (the tag name is just scope).
// tag::metrics-prometheus-output[]
[source,text,subs="attributes+"]
.Text response (partial):
----
# HELP classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine.
# TYPE classloader_loadedClasses_count gauge
classloader_loadedClasses_count{{prom-output-scope-prefix}scope="base",} 4878.0
# HELP classloader_unloadedClasses_total Displays the total number of classes unloaded since the Java virtual machine has started execution.
# TYPE classloader_unloadedClasses_total counter
classloader_unloadedClasses_total{{prom-output-scope-prefix}scope="base",} 0.0
# HELP classloader_loadedClasses_total Displays the total number of classes that have been loaded since the Java virtual machine has started execution.
# TYPE classloader_loadedClasses_total counter
classloader_loadedClasses_total{{prom-output-scope-prefix}scope="base",} 4878.0
# HELP vthreads_submitFailures Virtual thread submit failures since metrics start-up
# TYPE vthreads_submitFailures gauge
vthreads_submitFailures{{prom-output-scope-prefix}scope="base",} 0.0
# HELP vthreads_pinned Number of pinned virtual threads since metrics start-up
# TYPE vthreads_pinned gauge
vthreads_pinned{{prom-output-scope-prefix}scope="base",} 0.0
----
// end::metrics-prometheus-output[]
///////////////////////////////////////////////////////////////////////////////

// tag::curl-metrics-json[]
You can get the same data in JSON format.

[source,bash,subs="attributes+"]
.Verify the metrics endpoint with an HTTP accept header:
----
curl -H "Accept: application/json"  http://localhost:8080{metrics-endpoint}
----
// end::curl-metrics-json[]

// tag::base-metrics-json-output[]
    "gc.total;name=G1 Young Generation": 2,
    "cpu.systemLoadAverage": 11.0546875,
    "classloader.loadedClasses.count": 5124.0,
    "thread.count": 23.0,
    "classloader.unloadedClasses.total": 0,
    "vthreads.recentPinned": {
      "count": 0,
      "max": 0.0,
      "mean": 0.0,
      "elapsedTime": 0.0,
      "p0.5": 0.0,
      "p0.75": 0.0,
      "p0.95": 0.0,
      "p0.98": 0.0,
      "p0.99": 0.0,
      "p0.999": 0.0
    },
    "jvm.uptime": 138.233,
    "gc.time;name=G1 Young Generation": 0,
    "memory.committedHeap": 541065216,
    "thread.max.count": 26.0,
    "vthreads.pinned": 0,
    "cpu.availableProcessors": 8.0,
    "classloader.loadedClasses.total": 5124,
    "thread.daemon.count": 20.0,
    "memory.maxHeap": 8589934592,
    "memory.usedHeap": 2.774652E+7,
    "thread.starts": 28.0,
    "vthreads.submitFailures": 0
// end::base-metrics-json-output[]
// tag::vendor-metrics-json-output[]
  "vendor": {
    "requests.count": 3
  }

// end::vendor-metrics-json-output[]

// tag::get-single-metric[]
You can get a single metric by specifying the scope and name as query parameters in the URL.

[source,bash,subs="attributes+"]
.Get the Helidon `requests.count` {metric}:
----
curl -H "Accept: application/json"  'http://localhost:8080{metrics-endpoint}?scope=vendor&name=requests.count'
----

[source,json]
.JSON response:
----
{
  "requests.count": 6
}
----

// end::get-single-metric[]

// tag::built-in-metrics-discussion[]
The `base` {metrics} illustrated above provide some insight into the behavior of the JVM in which the server runs.

The `vendor` {metric} shown above gives an idea of the request traffic the server is handling. See the <<basic-and-extended-kpi,later section>> for more information on the basic and extended key performance indicator {metrics}.

// end::built-in-metrics-discussion[]

// tag::controlling[]
// tag::controlling-intro[]
// tag::controlling-intro-part-1[]
=== Controlling Metrics Behavior
By adding a `metrics` section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways.

*  <<disabling-entirely,Disable metrics subsystem entirely>>.
// end::controlling-intro-part-1[]
// tag::controlling-intro-part-2[]
*  Select whether to collect <<basic-and-extended-kpi,extended key performance indicator {metrics}>>.
*  Select which <<observing-vthreads,virtual threads {metrics}>> to report.
// end::controlling-intro-part-2[]
// end::controlling-intro[]

// tag::disabling-whole[]
// tag::disabling-whole-intro[]
[[disabling-entirely]]
==== Disabling Metrics Subsystem Entirely
You can disable the metrics subsystem entirely using configuration:
ifdef::mp-flavor[]
[source,properties]
.Configuration properties file disabling metrics
----
metrics.enabled=false
----
endif::mp-flavor[]
ifdef::se-flavor[]
[source,yaml]
.Configuration properties file disabling metrics
----
server:
  features:
    observe:
      observers:
        metrics:
          enabled: false
----
endif::se-flavor[]
// end::disabling-whole-intro[]

// tag::disabling-whole-summary[]
With metrics processing disabled, Helidon never updates any {metrics} and the `{metrics-endpoint}` endpoints respond with `404`.
// end::disabling-whole-summary[]
// end::disabling-whole[]

// tag::controlling-by-component[]
// tag::controlling-by-component-intro[]
[[enabling-disabling-by-component]]
==== Enabling and Disabling Metrics Usage by a Component
Helidon contains several components and integrations which register and update metrics.
Depending on how the component is written, you might be able to disable just that component's use of metrics:
[source,properties]
.Configuration properties file disabling a component's use of metrics
----
some-component.metrics.enabled=false
----
Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use.
// end::controlling-by-component-intro[]
// tag::controlling-by-component-summary[]
If you disable a component's use of metrics, Helidon does not register the component's metrics in the visible metrics registries nor do those metrics ever update their values. The response from the `/metrics` endpoint excludes that component's metrics.

Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings.
// end::controlling-by-component-summary[]
// end::controlling-by-component[]

// tag::controlling-by-registry[]
// tag::controlling-by-registry-intro[]
[[enabling-disabling-by-scope]]
==== Controlling Metrics By Registry Type and Metric Name
You can control the collection and reporting of metrics by registry type and metric name within registry type.

===== Disabling All Metrics of a Given Registry Type
To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration:

[source,properties]
.Disabling `base` and `vendor` metrics (properties format)
----
metrics.registries.0.type = base
metrics.registries.0.enabled = false
metrics.registries.1.type = vendor
metrics.registries.1.enabled = false
----

[source,yaml]
.Disabling `base` and `vendor` metrics (YAML format)
----
metrics:
  registries:
    - type: base
      enabled: false
    - type: vendor
      enables: false
----

===== Controlling Metrics by Metric Name
You can be even more selective. Within a registry type you can configure up to two regular expression patterns:

* one matching metric names to _exclude_, and
* one matching metric names to _include_.

Helidon updates and reports a metric only if two conditions hold:

* the metric name _does not_ match the `exclude` regex pattern (if you define one), and
* either
** there is no `include` regex pattern, or
** the metric name matches the `include` pattern.

[CAUTION]
====
Make sure any `include` regex pattern you specify matches _all_ the metric names you want to capture.
====
Suppose your application creates and updates a group of metrics with names such as `myapp.xxx.queries`, `myapp.xxx.creates`, `myapp.xxx.updates`, and `myapp.xxx.deletes` where `xxx` can be either `supplier` or `customer`.

The following example gathers all metrics _except_ those from your application regarding suppliers:
[source,properties]
.Disabling metrics by name (properties format)
----
metrics.registries.0.type = application
metrics.registries.0.filter.exclude = myapp\.supplier\..*
----

The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers:
[source,properties]
.Enabling metrics by name (properties format)
----
metrics.registries.0.type = application
metrics.registries.0.filter.include = myapp\..*\.updates
----

If you use the YAML configuration format, enclose the regex patterns in single-quote marks:
[source,yaml]
.Enabling metrics by name (YAML format)
----
metrics:
  registries:
    - type: application
      filter:
        include: 'myapp\..*\.updates'
----

The next example selects only your application's metrics while excluding those which refer to deletions:
[source,properties]
.Combining `include` and `exclude`
----
metrics.registries.0.type = application
metrics.registries.0.filter.include = myapp\..*
metrics.registries.0.filter.exclude = myapp\..*/deletes
----

Helidon would not update or report the metric `myapp.supplier.queries`, for example.
To  include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this:
[source.properties]
----
metrics.registries.0.type = application
metrics.registries.0.filter.include = myapp\..*\.updates|myapp\..*\.queries
metrics.registries.0.filter.exclude = myapp\..*/deletes
----

// end::controlling-by-registry-intro[]
// end::controlling-by-registry[]

// tag::KPI[]
[[basic-and-extended-kpi]]
==== Collecting Basic and Extended Key Performance Indicator (KPI) Metrics

Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator {metric}: a `Counter` of all requests received (`requests.count`).

Helidon {h1-prefix} also includes additional, extended KPI metrics which are disabled by default:

* current number of requests in-flight - a `Gauge` (`requests.inFlight`) of requests currently being processed
* long-running requests - a `Counter` (`requests.longRunning`) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds)
* load - a `Counter` (`requests.load`) measuring the number of requests worked on (as opposed to received)
* deferred - a `Gauge` (`requests.deferred`) measuring delayed request processing (work on a request was delayed after Helidon received the request)

You can enable and control these {metrics} using configuration:
ifdef::mp-flavor[]
[source,properties]
.Configuration properties file controlling extended KPI {metrics}
----
metrics.key-performance-indicators.extended = true
metrics.key-performance-indicators.long-running.threshold-ms = 2000
----
endif::mp-flavor[]
ifdef::se-flavor[]
[source,yaml]
----
server:
  features:
    observe:
      observers:
        metrics:
          key-performance-indicators:
            extended: true
            long-running:
              threshold-ms: 2000
----
endif::se-flavor[]
// end::KPI[]

// tag::virtualThreadsMetrics[]
[[observing-vthreads]]
==== Observing Virtual Threads Behavior
:vthreads-prefix: vthreads
Helidon maintains several {metrics} related to virtual threads as summarized in the next table. Helidon might rely on Java Flight Recorder (JFR) events and JMX MXBeans in computing the {metric} values. Be aware that limitations or changes in the values provided by these sources are outside the control of Helidon.

.{metrics_uc} for Virtual Threads
[cols="2,5,3,1"]
|===
| {metric_uc} name | Usage | Source | Reported by default

| `{vthreads-prefix}.count` | Current number of active virtual threads. | JFR `jdk.virtualThreadStart` and `jdk.virtualThreadEnd` events| no
| `{vthreads-prefix}.pinned` | Number of times virtual threads have been pinned. | JFR `jdk.virtualThreadPinned` event | yes
| `{vthreads-prefix}.recentPinned` | Distribution of the duration of thread pinning. ^1^ | JFR `jdk.virtualThreadPinned` event | yes
| `{vthreads-prefix}.started` | Number of virtual threads started. | JFR `jdk.virtualThreadStart` event | no
| `{vthreads-prefix}.submitFailed` | Number of times submissions of a virtual thread to a platform carrier thread failed. | JFR `jdk.virtualThreadSubmitFailed` event | yes
|===
^1^ Distribution summaries can discard stale data, so the `recentPinned` summary might not reflect all thread pinning activity.

// tag::virtualThreadsMetricsConfig[]
==== Configuring Virtual Threads {metrics_uc}
===== Disabling Virtual Threads {metrics_uc} Entirely
Gathering data to compute the {metrics} for virtual threads is designed to be as efficient as possible, but doing so still imposes a small load on the server and by default Helidon exposes only the {metrics} related to virtual threads noted in the table above.

To disable all {metrics} describing virtual threads, include a config setting as shown in the following example:

.Disabling virtual thread metrics entirely
ifdef::mp-flavor[]
[source,properties]
----
metrics.virtual-threads.enabled = false
----
endif::mp-flavor[]
ifdef::se-flavor[]
[source,yaml]
----
metrics:
  virtual-threads:
    enabled: false
----
endif::se-flavor[]

===== Controlling Measurements of Pinned Virtual Threads
Helidon measures pinned virtual threads only when the thread is pinned for a length of time at or above a threshold. Control the threshold by configuring the threshold as shown in the example below.

.Setting virtual thread pinning threshold to 100 ms
ifdef::mp-flavor[]
[source,properties]
----
metrics.virtual-threads.pinned.threshold=PT0.100S
----
endif::mp-flavor[]
ifdef::se-flavor[]
[source,yaml]
----
metrics:
  virtual-threads:
    pinned:
      threshold: PT0.100S
----
endif::se-flavor[]
The threshold value is a `Duration` string, such as `PT0.100S` for 100 milliseconds.

===== Controlling Virtual Thread Counts
For performance reasons Helidon does not by default report the {metrics} related to the count of virtual threads.
Enable these {metrics} using configuration.

[CAUTION]
Enabling virtual thread counts can degrade the performance of your server. Do so with care.

.Enabling Virtual Thread Counts
ifdef::mp-flavor[]
[source,properties]
----
metrics.virtual-threads.count.enabled=true
----
endif::[]
ifdef::se-flavor[]
[source,yaml]
----
metrics:
  virtual-threads:
    count:
      enabled: true
----
endif::[]
// end::virtualThreadsMetricsConfig[]

// end::virtualThreadsMetrics[]
// end::controlling[]

// tag::metrics-metadata[]
=== Metrics Metadata

Each {metric} has associated metadata that includes:

1. name: The name of the {metric}.
2. units: The unit of the {metric} such as time (seconds, milliseconds), size (bytes, megabytes), etc.
3. a description of the {metric}.

You can get the metadata for any scope, such as `{metrics-endpoint}?scope=base`, as shown below:

[source,bash, subs="attributes+"]
.Get the metrics metadata using HTTP OPTIONS method:
----
 curl -X OPTIONS -H "Accept: application/json"  'http://localhost:8080{metrics-endpoint}?scope=base'
----

[source,json]
.JSON response (truncated):
----
{
   "classloader.loadedClasses.count": {
      "type": "gauge",
      "description": "Displays the number of classes that are currently loaded in the Java virtual machine."
    },
   "jvm.uptime": {
      "type": "gauge",
      "unit": "seconds",
      "description": "Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started."
    },
   "memory.usedHeap": {
      "type": "gauge",
      "unit": "bytes",
      "description": "Displays the amount of used heap memory in bytes."
    }
}
----

// end::metrics-metadata[]


// tag::k8s-and-prometheus-integration[]

=== Integration with Kubernetes and Prometheus
==== Kubernetes Integration
The following example shows how to integrate the Helidon {h1-prefix} application with Kubernetes.

[source,bash,subs="attributes+"]
.Stop the application and build the docker image:
----
docker build -t helidon-metrics-{flavor-lc} .
----

[source,yaml,subs="attributes+"]
.Create the Kubernetes YAML specification, named `metrics.yaml`, with the following content:
----
kind: Service
apiVersion: v1
metadata:
  name: helidon-metrics # <1>
  labels:
    app: helidon-metrics
  annotations:
    prometheus.io/scrape: "true" # <2>
spec:
  type: NodePort
  selector:
    app: helidon-metrics
  ports:
    - port: 8080
      targetPort: 8080
      name: http
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: helidon-metrics
spec:
  replicas: 1 # <3>
  selector:
    matchLabels:
      app: helidon-metrics
  template:
    metadata:
      labels:
        app: helidon-metrics
        version: v1
    spec:
      containers:
        - name: helidon-metrics
          image: helidon-metrics-{flavor-lc}
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
----
<1> A service of type `NodePort` that serves the default routes on port `8080`.
<2> An annotation that will allow Prometheus to discover and scrape the application pod.
<3> A deployment with one replica of a pod.


[source,bash]
.Create and deploy the application into Kubernetes:
----
kubectl apply -f ./metrics.yaml
----

[source,bash]
.Get the service information:
----
kubectl get service/helidon-metrics
----

[source,bash]
----
NAME             TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
helidon-metrics   NodePort   10.99.159.2   <none>        8080:31143/TCP   8s # <1>
----
<1> A service of type `NodePort` that serves the default routes on port `31143`.

[source,bash]
.Verify the metrics endpoint using port `30116`, your port will likely be different:
----
curl http://localhost:31143/metrics
----

NOTE: Leave the application running in Kubernetes since it will be used for Prometheus integration.

==== Prometheus Integration

The metrics service that you just deployed into Kubernetes is already annotated with `prometheus.io/scrape:`.  This will allow
Prometheus to discover the service and scrape the metrics.  This example shows how to install Prometheus
into Kubernetes, then verify that it discovered the Helidon metrics in your application.

[source,bash]
.Install Prometheus and wait until the pod is ready:
----
helm install stable/prometheus --name metrics
export POD_NAME=$(kubectl get pods --namespace default -l "app=prometheus,component=server" -o jsonpath="{.items[0].metadata.name}")
kubectl get pod $POD_NAME
----

You will see output similar to the following.  Repeat the `kubectl get pod` command until you see `2/2` and `Running`. This may take up to one minute.

[source,bash]
----
metrics-prometheus-server-5fc5dc86cb-79lk4   2/2     Running   0          46s
----

[source,bash]
.Create a port-forward, so you can access the server URL:
----
kubectl --namespace default port-forward $POD_NAME 7090:9090
----

Now open your browser and navigate to `http://localhost:7090/targets`.  Search for helidon on the page, and you will see your
Helidon application as one of the Prometheus targets.

==== Final Cleanup

You can now delete the Kubernetes resources that were just created during this example.

[source,bash]
.Delete the Prometheus Kubernetes resources:
----
helm delete --purge metrics
----

[source,bash]
.Delete the application Kubernetes resources:
----
kubectl delete -f ./metrics.yaml
----

// end::k8s-and-prometheus-integration[]
