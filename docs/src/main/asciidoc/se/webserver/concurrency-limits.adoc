///////////////////////////////////////////////////////////////////////////////

    Copyright (c) 2025 Oracle and/or its affiliates.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

///////////////////////////////////////////////////////////////////////////////

= Concurrency Limits
:description: Helidon SE Concurrency Limits
:feature-name: Concurrency Limits
:microprofile-bundle: false
:keywords: helidon, se, performance, concurrency, limits
:rootdir: {docdir}/../..

include::{rootdir}/includes/se.adoc[]

== Introduction

With the introduction of virtual threads, Helidon is able to create a new
thread per request with the only limit being the available memory on the system.
In some situations, this scenario is not ideal as it can increase concurrency
beyond the capabilities of some other components in the system, such as a database,
a network link, etc.

In those cases, and when scaling of those components is not feasible or simply not desirable,
it may be beneficial
to limit the number of concurrent requests accepted by the Helidon webserver in
order to improve the overall experience. When doing so, it should also be possible
to establish rules for those requests that cannot be serviced immediately,
as well as how to grow or shrink the number of _permits_ available in the system.

== Setting Concurrency Limits

Helidon now includes support for two independent concurrency limit strategies:
fixed and AIMD (Arithmetic Increase Multiplicative Decrease) as well as an SPI
to provide alternative `LimitProvider` implementations.

Concurrency limits can be configured directly on the Webserver or as a _feature_.
When set at the Webserver level, they will affect all traffic inbound to the server,
effectively limiting the number of requests processed by the internal _listener_
&mdash;or listeners if more than one socket is defined. When set as a feature,
they will work as a filter applied after routing and only to HTTP traffic. In
most cases, setting limits at the Webserver level will be simpler and most
effective.

The following example uses a fixed concurrency strategy established at the
Webserver level &mdash;impacting only the _default_ socket&mdash; that limits
the number of concurrent requests to 1000, a queue of 200 requests to accommodate
potential request bursts and a queue timeout of 1 second:
[source,yaml]
----
server:
  concurrency-limit:
    fixed:
      permits: 1000
      queue-length: 200
      queue-timeout: PT1S
----

With this configuration, after all 1000 permits are consumed, subsequent requests
will be queued, if space is available, and any request that sits in the queue for more than
1 second will be rejected.

The same use case but defined as a feature will look as follows:

[source,yaml]
----
server:
  features:
    limits:
      concurrency-limit:
        fixed:
          permits: 1000
          queue-length: 200
          queue-timeout: PT1S
----

As described above, when configured as a feature, the limits will only apply to
HTTP traffic and will execute after HTTP routing.

Instead of fixing the number of permits to a given value, the AIMD strategy
allows the set of permits to grow arithmetically and shrink multiplicatively
as needed, based on the actual time that it takes to process requests. AIMD
can dynamically adjust the number of available permits to ensure a certain
_quality of service_, possibly for a subset of all the requests received.
It is generally preferred to serve a subset of clients efficiently than
all clients inefficiently, and this type of trade-off can be defined using
an AIMD strategy. For example,

[source,yaml]
----
server:
  concurrency-limit:
    aimd:
      min-limit: 100
      max-limit: 1000
      initial-limit: 500
      timeout: "PT0.5S"
      backoff-ratio: 0.75
----

With this configuration, the initial number of permits starts at 500 and
can vary between 100 and 1000. The timeout set at 500 milliseconds is used
to determine how to limit concurrency: if a request completes under this
limit, then the number of permits can increase by one up to the maximum;
if a request fails or if it completes over this limit, then the number
of permits shrinks using the backoff ratio (by 75% in our example) up
to the minimum.

AIMD also supports queueing and queueing timeouts, so if the maximum size
is reached, it is still possible to accept (enqueue) a request as long
as it is processed within the queueing timeout period. Here is a variation
of the example above, but with a queue of size 300 and a queue timeout of
1 second:

[source,yaml]
----
server:
  concurrency-limit:
    aimd:
      min-limit: 100
      max-limit: 1000
      initial-limit: 500
      timeout: "PT0.5S"
      backoff-ratio: 0.75
      queue-length: 300
      queue-timeout: PT1S
----

NOTE: Queues can be useful to accommodate short bursts of
requests that would otherwise be rejected when the number of permits
is exhausted. Queueing is disabled by default in both fixed and
AIMD strategies, so `queue-length` must be set to a positive number
to enable this feature.

Neither of the two strategies shown above enables queues by default.

For more information about configuring these Concurrency Limit
strategies see:

- xref:{rootdir}/config/io_helidon_common_concurrency_limits_FixedLimit.adoc[FixedLimit]
- xref:{rootdir}/config/io_helidon_common_concurrency_limits_AimdLimit.adoc[AimdLimit]

== Metrics

The Concurrency Limit module also has built-in support for metrics in order
to monitor the chosen strategy. These metrics are disabled by default,
but can be enabled as follows:

[source,yaml]
----
server:
  concurrency-limit:
    fixed:
      permits: 1000
      queue-length: 200
      queue-timeout: PT1S
      enable-metrics: true       # turn on metrics!
----

The following tables describe the metrics that are available for each of the
strategies described above. A metric tag `socketName=<name-of-socket>` is used to
group metrics that correspond to a particular socket; for simplicity this metric tag
is _omitted_ for the default socket. All metrics provided by the Concurrency Limit
module are in **vendor** scope.

.Fixed
|===
|Name |Description

|`fixed_queue_length`
|Gauge that returns the number of requests waiting on the queue at a certain time

|`fixed_rejected_requests`
|Gauge that returns the number of requests that have been rejected so far

|`fixed_rtt`
|Distribution summary of round-trip times, excluding any time waiting in the queue

|`fixed_queue_wait_time`
|Distribution summary of queue wait times

|`fixed_concurrent_requests`
|Gauge that returns the number of requests being processed at a certain time
|===

.AIMD
|===
|Name |Description

|`aimd_queue_length`
|Gauge that returns the number of requests waiting on the queue at a certain time

|`aimd_rejected_requests`
|Gauge that returns the number of requests that have been rejected so far

|`aimd_rtt`
|Distribution summary of round-trip times, excluding any time waiting in the queue

|`aimd_queue_wait_time`
|Distribution summary of queue wait times

|`aimd_concurrent_requests`
|Gauge that returns the number of requests being processed at a certain time

|`aimd_limit`
|Gauge that returns the actual limit at a certain time
|===

For more information regarding metrics support in Helidon and the dependencies that are
required for metrics to work, see xref:{metrics-page}[Helidon Metrics].

== Tracing
The Concurrency Limit component supports tracing.
If you enable tracing for the strategy you configure, any time Helidon queues a request waiting for an available worker thread it creates a span representing the request's waiting time.
Concurrency limit tracing is disabled by default. Enable it using configuration:

[source,yaml]
----
server:
  concurrency-limit:
    fixed:
      permits: 1000
      queue-length: 200
      queue-timeout: PT1S
      enable-tracing: true       # <1>
----
<1> Turns on tracing to add a span for queued wait time.

Be sure to add a dependency in your project for one of the Helidon tracing implementations. See the xref:{tracing-page}[Helidon tracing] documentation for more information.

== Custom Listeners for Concurrency Limit Operations
Helidon itself supports metrics and tracing for concurrency limit operations. Applications can also register their own logic which Helidon invokes at key points as it enforces concurrency limits.

Implement the link:{webserver-javadoc-base-url}/io/helidon/webserver/http/spi/HttpLimitListenerProvider.html[`HttpLimitListenerProvider`] interface so it provides listeners that respond as you need as limits are applied to HTTP requests.

See also the Javadoc for link:{concurrency-limits-javadoc-base-url}/io/helidon/common/concurrency/limits/spi/LimitAlgorithmListener.html[`LimitAlgorithmListener`] for details on how and when Helidon invokes the listeners.